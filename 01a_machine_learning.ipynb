{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative machine learning - Machine Learning\n",
    "\n",
    "### Author: Philippe Esling (esling@ircam.fr)\n",
    "\n",
    "In this course we will cover\n",
    "1. A [first definition](#definition) on the concept of machine learning\n",
    "2. An introduction to a simple problem of [linear regression](#regression)\n",
    "4. A detailed implementation of [simple linear regression](#linear)\n",
    "3. An explanation on [model capacity and overfitting](#capacity)\n",
    "4. Two [exercises](#exercises) to explore regression and classification\n",
    "4. An introduction to the [audio datasets](#audio) that we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "<a id=\"definition\"></a>\n",
    "## Defining machine learning\n",
    "\n",
    "In all natural process, there exists complex relations between sets $\\mathcal{X} \\mapsto \\mathcal{Y}$. This can relate some objects with their names, or a cause to a consequence. In most cases, _we do not know the precise relations_ between these sets, all we have is _observations_ such as pairs $(x,y)$, composed of input data $x \\in \\mathcal{X}$, which have a corresponding expected output $y \\in \\mathcal{Y}$. The overarching goal of machine learning is to approximate such _unknown processes_ as a function $\\mathcal{F}_{\\theta}$, which _transforms_ input data $x$ into output data $y$.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/01_machine_learning_basic.png\" align=\"center\"/>\n",
    "</center>\n",
    "\n",
    "Hence, machine learning aims to understand and model the relationship between some (usually complex and high-dimensional) inputs $\\mathbf{x}\\in\\mathcal{X}\\subset\\mathbb{R}^{\\mathcal{X}}$ and outputs $\\mathbf{y}\\in\\mathcal{Y}\\subset\\mathbb{R}^{\\mathcal{Y}}$, given by a set of data examples $\\mathcal{D}=\\left\\{(x_1,y_1),\\cdots,(x_N,y_N)\\right\\}$. This is achieved by defining a parametric model $f_{\\mathbf{\\theta}}\\in\\mathcal{F}$ inside a family of functions $\\mathcal{F}$, which depends on parameters $\\mathbf{\\theta} \\in \\mathbf{\\Theta}$ and that could approximate the underlying relationship. The _learning_ aspect refers to the adjustment of the parameters $\\mathbf{\\theta}$ in order to obtain the best approximation of the given task\n",
    "$$\n",
    "\\begin{equation}\n",
    "f_{\\mathbf{\\theta}}(\\mathbf{x}) = \\bar{\\mathbf{y}}\\approx \\mathbf{y}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Hence, the major elements that we have to define in any machine learning problems are\n",
    "1. **Dataset** : $\\mathcal{D}=\\left\\{(x_1,y_1),\\cdots,(x_N,y_N)\\right\\}$. This dataset has to be representative of the relation $f:\\mathcal{X} \\mapsto \\mathcal{Y}$ that we are looking to model\n",
    "2. **Model** : Our parametric approximation $\\bar{\\mathbf{y}} = f_{\\mathbf{\\theta}}(\\mathbf{x})$, where the choice of family $f_{\\mathbf{\\theta}}\\in\\mathcal{F}$ is critical\n",
    "3. **Loss** : $\\mathcal{L}\\left( \\bar{\\mathbf{y}}, \\mathbf{y} \\mid f_{\\theta}, \\theta \\right)$ allows to measure the amount of errors made by our model\n",
    "4. **Optimization** : Method to find $\\theta^{*}\\in\\Theta$ so that our model minimizes the loss\n",
    "$$\\theta^{*}= \\underset{\\theta}{\\text{argmin }} \\mathcal{L}\\left( \\bar{\\mathbf{y}}, \\mathbf{y} \\mid f_{\\theta}, \\theta \\right)$$\n",
    "\n",
    "\n",
    "To observe this idea in simple setups, we are going to use the `numpy` library and also initialize the homemade course library `cml` and style for future plotting and exercise. We also set the random generator to a fixed point with `rng = np.random.RandomState(1)`, to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c6e057d5-20b4-4c5d-a75e-95c416a16316\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"c6e057d5-20b4-4c5d-a75e-95c416a16316\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"static/extensions/panel/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.2.min.js\", \"https://unpkg.com/@holoviz/panel@1.6.2/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c6e057d5-20b4-4c5d-a75e-95c416a16316\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.holoviz.org/panel/1.6.2/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      inject_raw_css(\"/*\\n ~ CML // Creative Machine Learning ~\\n mml.css : CSS styling information for Panel and Bokeh\\n \\n This file defines the main CSS styling information for the CML course\\n \\n Author               :  Philippe Esling\\n                        <esling@ircam.fr>\\n*/\\n\\nbody {\\n  display: flex;\\n  height: 100vh;\\n  margin: 0px;\\n  overflow-x: hidden;\\n  overflow-y: hidden;\\n}\\n\\n.bk-root .bk, .bk-root .bk:before, .bk-root .bk:after {\\n  font-family: \\\"Josefin Sans\\\";\\n}\\n\\nimg {\\n  max-width: 100%;\\n}\\n\\n#container {\\n  padding:0px;\\n  height:100vh;\\n  width: 100vw;\\n  max-width: 100vw;\\n}\\n\\n#sidebar .mdc-list {\\n  padding-left: 5px;\\n  padding-right: 5px;\\n}\\n\\n.mdc-drawer-app-content {\\n  flex: auto;\\n  position: relative;\\n  overflow: hidden;\\n}\\n\\n.mdc-drawer {\\n  background: #FAFAFA; /* GRAY 50 */\\n}\\n\\n.mdc-drawer-app-content {\\n  margin-left: 0 !important;\\n}\\n\\n.title-bar {\\n  display: contents;\\n  justify-content: center;\\n  align-content: center;\\n  width: 100%;\\n}\\n\\n.mdc-top-app-bar .bk-menu {\\n  color: black\\n}\\n\\n.app-header {\\n  display: contents;\\n  padding-left: 10px;\\n  font-size: 1.25em;\\n}\\n\\nimg.app-logo {\\n  padding-right: 10px;\\n  font-size: 28px;\\n  height: 30px;\\n  max-width: inherit;\\n  padding-top: 12px;\\n  padding-bottom: 6px;\\n}\\n\\n#app-title {\\n  padding-right: 12px;\\n  padding-left: 12px;\\n}\\n\\n.title {\\n  font-family: \\\"Josefin Sans\\\";\\n  color: #fff;\\n  text-decoration: none;\\n  text-decoration-line: none;\\n  text-decoration-style: initial;\\n  text-decoration-color: initial;\\n  font-weight: 400;\\n  font-size: 2em;\\n  line-height: 2em;\\n  white-space: nowrap;\\n}\\n\\n.main-content {\\n  overflow-y: scroll;\\n  overflow-x: auto;\\n}\\n\\n#header {\\n  position: absolute;\\n  z-index: 7;\\n}\\n\\n#header-items {\\n  width: 100%;\\n  margin-left:15px;\\n}\\n\\n.pn-busy-container {\\n  align-items: center;\\n  justify-content: center;\\n  display: flex;\\n}\\n\\n.mdc-drawer__content {\\n  overflow-x: hidden;\\n}\\n.mdc-drawer__content, .main-content {\\n  padding: 12px;\\n}\\n\\n.main-content {\\n  height: calc(100vh - 88px);\\n  max-height: calc(100vh - 88px);\\n  padding-right: 32px;\\n}\\n\\nbutton.mdc-button.mdc-card-button {\\n  color: transparent;\\n  height: 50px;\\n}\\n\\np.mdc-button {\\n  display: none;\\n}\\n\\ndiv.mdc-card {\\n  border-radius: 0px\\n}\\n\\n.mdc-card .card-header {\\n  display: flex;\\n}\\n\\n.mdc-card-title {\\n  font-family: \\\"Josefin Sans\\\";\\n  font-weight: bold;\\n  align-items: center;\\n  display: flex !important;\\n  position: relative !important;\\n}\\n\\n.mdc-card-title:nth-child(2) {\\n  margin-left: -1.4em;\\n}\\n\\n.pn-modal {\\n  overflow-y: scroll;\\n  width: 100%;\\n  display: none;\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n}\\n\\n.pn-modal-content {\\n  font-family: \\\"Josefin Sans\\\";\\n  background-color: #0e0e0e;\\n  margin: auto;\\n  margin-top: 25px;\\n  margin-bottom: 25px;\\n  padding: 15px 20px 20px 20px;\\n  border: 1px solid #888;\\n  width: 80% !important;\\n}\\n\\n.pn-modal-close {\\n  position: absolute;\\n  right: 25px;\\n  z-index: 100;\\n}\\n\\n.pn-modal-close:hover,\\n.pn-modal-close:focus {\\n  color: #000;\\n  text-decoration: none;\\n  cursor: pointer;\\n}\\n\\n.custom_button_bokeh button.bk-btn.bk-btn-default {\\n    font-size:48pt;\\n    background-color: #05b7ff;\\n    border-color: #05b7ff;\\n}\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1fd431da-1fe4-43aa-9b7b-af0c5aadadbc'>\n",
       "  <div id=\"c0ddb5d2-b9e3-40a0-bd48-0a7e2b961a02\" data-root-id=\"1fd431da-1fe4-43aa-9b7b-af0c5aadadbc\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"b6897d4e-d947-4c4f-b9b3-74ff0210b896\":{\"version\":\"3.7.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"1fd431da-1fe4-43aa-9b7b-af0c5aadadbc\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"3c9083f1-25c8-4108-940c-a91d178896e3\",\"attributes\":{\"plot_id\":\"1fd431da-1fe4-43aa-9b7b-af0c5aadadbc\",\"comm_id\":\"3e530471372c4eb7a96b97f8a44dad08\",\"client_comm_id\":\"d6fb572a62914abf9cf764297b9289d1\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"b6897d4e-d947-4c4f-b9b3-74ff0210b896\",\"roots\":{\"1fd431da-1fe4-43aa-9b7b-af0c5aadadbc\":\"c0ddb5d2-b9e3-40a0-bd48-0a7e2b961a02\"},\"root_ids\":[\"1fd431da-1fe4-43aa-9b7b-af0c5aadadbc\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1fd431da-1fe4-43aa-9b7b-af0c5aadadbc"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cml.plot import initialize_bokeh\n",
    "from cml.panel import initialize_panel\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "from bokeh.io import show\n",
    "initialize_bokeh()\n",
    "initialize_panel()\n",
    "set_nb_theme(\"onedork\")\n",
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "<a id=\"regression\"></a>\n",
    "## Simple learning problem\n",
    "\n",
    "Imagine that a certain process somewhere follows the form of a quadratic relationship\n",
    "\n",
    "$$\n",
    " y = a x^{2} + bx + c \n",
    "$$\n",
    "\n",
    "In this case, all the **unknown parameters** are that of a polynomial model, therefore we have $\\theta = \\{a, b, c\\}$. However, this is clearly an ideal (clean) case, whereas in natural observations, there might be some noise in our observations\n",
    "\n",
    "$$\n",
    " y = a x^{2} + bx + c +\\epsilon \\text{ with } \\epsilon \\in [-0.1, 0.1]\n",
    "$$\n",
    "\n",
    "An example of such noisy observations for different parameters is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters to our function\n",
    "eps = 0.1\n",
    "a, b, c = 5, 2, 1\n",
    "# Generating the corresponding data\n",
    "x = np.linspace(0, 1, 100)\n",
    "poly = np.poly1d([a, b, c])\n",
    "epsilon = np.random.uniform(-eps, eps, x.shape)\n",
    "y = poly(x) + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084cd86e4d4e46a682ea7dff212d6f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'3c2bc2a5-bbde-4e5f-a063-7f5509bf6610': {'version…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.plot import center_plot, scatter\n",
    "plot = (center_plot(scatter(x, y, title=\"Simple quadratic problem\", toolbar_location=\"left\")))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "Now our main problem is that this function can follow different types of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "params = [[5, -5, 4], [-2, 1, 0], [0.1, 1, 1]]\n",
    "# Generating the x axis\n",
    "x = np.linspace(0, 1, 100)\n",
    "plots = []\n",
    "for ind, param in enumerate(params):\n",
    "    poly = np.poly1d(param)\n",
    "    epsilon = np.random.uniform(-eps, eps, x.shape)\n",
    "    y = poly(x) + epsilon\n",
    "    plots.append(scatter(x, y, title=\"Problem \"+(str(ind+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18865319839b448290b04670e609c9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'0b2f353a-8a4a-4107-86c9-9cb539cc4596': {'version…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.models import Div\n",
    "from bokeh.layouts import column, row\n",
    "plot = center_plot(column(Div(text = \"Observing different problems\", styles={'font-size': '250%'}), row(*plots)))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "In real-life settings, this function can also have different levels of noise, as exemplified in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "params = [3, 0, 1]\n",
    "noise_levels = [0.1, 1.0, 8.0]\n",
    "# Generating the x axis\n",
    "x = np.linspace(0, 1, 100)\n",
    "plots = []\n",
    "for ind, noise_level in enumerate(noise_levels):\n",
    "    poly = np.poly1d(params)\n",
    "    epsilon = np.random.uniform(-noise_level, noise_level, x.shape)\n",
    "    y = poly(x) + epsilon\n",
    "    plots.append(scatter(x, y, title=\"Problem \"+(str(ind+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22db81a9fb1640098b092d5c719cae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'675f679e-17d5-4521-923e-4f5b6fd53b1b': {'version…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = center_plot(column(Div(text = \"Different amounts of noise\", styles={'font-size': '250%'}), row(*plots)))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "To summarize, we will have some observations of a function, and we would like to optimize a function that gets as close as possible to the real function that generated this data. Here, we plot the real function and also _subsample_ our number of observations (having only a few points to find the corresponding function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ff8afe4ab942beb713e24b1276258f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'53e99afc-512a-470c-900f-caeba04e6a7e': {'version…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the data and subsampling\n",
    "x_all = np.linspace(0, 1, 100); x_plot = np.linspace(0, 1, 100)\n",
    "rng.shuffle(x_all); x = np.sort(x_all[:50])\n",
    "poly = np.poly1d([3,0,1])\n",
    "# Adding some external noise\n",
    "epsilon = np.random.uniform(-0.2,0.2,x.shape)\n",
    "y = poly(x)+ epsilon\n",
    "p = scatter(x, y, title=\"Learning problem with groundtruth\")\n",
    "p.line(x_plot, poly(x_plot), line_width=6, line_alpha=0.6, color=\"green\", legend_label=r\"True function\")\n",
    "plot = (center_plot(p))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Summarizing our observations (interactive)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9de1e9eb13b495395f15178211d940b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'9c5c518f-684a-4a61-8a9c-09bd765629ad': {'version…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.tasks import RegressionPolynomial\n",
    "explorer = RegressionPolynomial()\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "## Using learning libraries (`scikit-learn`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "To get a first grip on what machine learning does, we will rely on the `scikit-learn` library. This contains already coded models and learning procedure, that will allow us to _learn_ the parameters of this unknown function.\n",
    "\n",
    "Here we already know that we want to use a `PolynomialFeatures` model to perfom `LinearRegression` and that this polynomial should be of degree 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Our data to fit\n",
    "X = x[:, np.newaxis]\n",
    "# Degree of our polynomial\n",
    "degree = 30;\n",
    "# Create our polynomial model for regression\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "# Fit the parameters of this model\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "Now that we have trained the model, we can perform _predictions_ from it, meaning that we can infer the output of the function at values that we did not observe originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error : 0.07564946859775724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0300690aaba84f55ab306a4c3ad7e8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'1ba77cbc-1c3f-4f9d-9432-e093a9d77c08': {'version…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference points (not observed)\n",
    "X_plot = x_plot[:, np.newaxis]\n",
    "# Predict the values\n",
    "y_plot = model.predict(X_plot)\n",
    "# Compute the error of our model at observed points\n",
    "Y_model_err = np.sqrt(np.mean(np.square(y-model.predict(X))))\n",
    "print(f'Model error : {Y_model_err}')\n",
    "# Plot the result\n",
    "p = scatter(x, y, title=\"Training a scikit-learn model\")\n",
    "p.line(x_plot, poly(x_plot), line_width=6, line_alpha=0.6, color=\"red\", legend_label=r\"Trained model\")\n",
    "plot = (center_plot(p))\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from cml.tasks import RegressionPolynomialSolver\n",
    "explorer = RegressionPolynomialSolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1d5bdc9a564bb4a58ec765b359ab1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'4041802a-1ccb-4003-bccb-7127b17153c2': {'version…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve(x, y, degree):\n",
    "    X = x[:, np.newaxis]\n",
    "    # Create our polynomial model for regression\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    # Fit the parameters of this model\n",
    "    model.fit(X, y)\n",
    "    # Predict the values\n",
    "    x_predict = np.linspace(np.min(x), np.max(x), 200)[:, np.newaxis]\n",
    "    y_model = model.predict(x_predict)\n",
    "    return x_predict[:, 0], y_model #np.array(jnp.zeros(y_model.shape))\n",
    "\n",
    "explorer.solve = solve\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "<a id=\"linear\"></a>\n",
    "# Simple linear regression \n",
    "\n",
    "As discussed previously, regression allows to model the relationships that exist between inputs $\\mathbf{x}\\in\\mathbb{R}^{n}$ and a continuous output $y\\in\\mathbb{R}$. In the case of **linear** regression, we assume that the data that we observe comes from a linear relationship in the input, so that\n",
    "$$y = w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n + \\epsilon$$\n",
    "with $\\epsilon$ exhibiting the *observation noise* (also called *residual error*) that is always present in measurements.\n",
    "\n",
    "To understand how we could learn a model approximating this relationship, we start with the case of *simple* linear regression, where $\\mathbf{x}\\in\\mathbb{R}$. This implies that our model will follow\n",
    "$$\\bar{y} = w_0 + w_1 x$$\n",
    "\n",
    "We will measure the errors made by our model by using the Mean Squared Error (MSE) loss, defined as \n",
    "$$\\mathcal{L}_{MSE}\\left( \\bar{\\mathbf{y}},\\theta \\right) = \\sum_{i=1}^{n} \\left| y_{i} - \\bar{y}_{i} \\right|^{2} = \\sum_{i=1}^{n} \\left| y_{i} - (w_{0} + w_{1} x_{i}) \\right|^{2}$$\n",
    "\n",
    "Then our goal is to find the most adequate set of parameters $\\theta = \\{w_{0}, w_{1}\\}$, which are those that minimize the MSE loss defined previously. Therefore, we aim to obtain\n",
    "$$\\theta^{*}= \\underset{\\theta}{\\text{argmin }} \\mathcal{L}\\left( \\bar{\\mathbf{y}}, \\mathbf{y} \\mid f_{\\theta}, \\theta \\right)$$\n",
    "\n",
    "To do so, we will implement the **gradient descent** algorithm discussed in the course.\n",
    "\n",
    "## Manual implementation - `NumPy`\n",
    "\n",
    "We start by performing a *full manual implementation*, in the sense that we need to manually derive the gradient in order to apply the gradient descent updates. To do so, we will rely on [NumPy](https://numpy.org/), which is a fundamental library for numerical computing offering support for N-dimensional arrays and scientific computing tasks, such as linear algebra, statistical analysis, and matrix manipulation. We strongly encourage you to learn NumPy through the set of [tutorials](https://numpy.org/learn/). For the sake of this introductory tutorial, we will provide the explanation for all of the functions that we will use in this first exercise. After that exercise, we will assume for the rest of the course that knowledge of Numpy should be found online. \n",
    "\n",
    "We start by import libraries (`NumPy`) and set a random seed to ensure that the random number generator produces always a reproducible series of random numbers.\n",
    "\n",
    "**Used functions**\n",
    "- `np.random.seed`: sets the seed for the NumPy random number generator. [Documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Generate a synthetic dataset.\n",
    "\n",
    "For the sake of this exercise, we will generate the data ourselves, so that we know the true values that we are looking for in advance. Hence, we define a linear relationship following\n",
    "$$y = w^{t}_0 + w^{t}_1 x + \\epsilon$$\n",
    "\n",
    "**Used functions**\n",
    "- `np.random.rand`: generates an array of random numbers uniformly distributed over [0, 1). [Documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html)\n",
    "- `np.random.randn`: generates an array of random numbers from the standard normal distribution (mean 0, variance 1). [Documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html)\n",
    "- `np.ones`: generates an array of ones with a specified shape. [Documentation](https://numpy.org/doc/stable/reference/generated/numpy.ones.html)\n",
    "- `np.c_`: concatenates arrays along the second axis. [Documentation](https://numpy.org/doc/stable/reference/generated/numpy.c_.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "true_w0 = 2\n",
    "true_w1 = 3\n",
    "n_obs = 100\n",
    "x = [0, 1]\n",
    "# Input to model\n",
    "x = np.linspace(x[0], x[1], n_obs + 1)\n",
    "# Output (target)\n",
    "y = (true_w1 * x + true_w0) + (np.random.randn(n_obs + 1) * 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Computing the MSE loss\n",
    "\n",
    "We will measure the errors made by our model by using the Mean Squared Error (MSE) loss, defined as \n",
    "$$\\mathcal{L}_{MSE}\\left( \\bar{\\mathbf{y}},\\theta \\right) = \\sum_{i=1}^{n} \\left| y_{i} - \\bar{y}_{i} \\right|^{2} = \\sum_{i=1}^{n} \\left| y_{i} - (w_{0} + w_{1} x_{i}) \\right|^{2}$$\n",
    "\n",
    "This will allow us to evaluate the performances of our model, but is also the basis for the following gradient descent algorithm.\n",
    "\n",
    "**Used functions**\n",
    "- `np.sum`: computes the sum of the provided array (optionally across a provided `axis`). [Documentation](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "def mse_loss(y, y_bar):\n",
    "    return np.sum((y - y_bar) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Implement the gradient descent algorithm.\n",
    "\n",
    "As seen in the course Initialize the weight $w_1$ and bias $w_0$ to small random values\n",
    "1. Evaluate the predictions made by our model \n",
    "$$\\hat{y} = w_{1}x + w_0$$\n",
    "2. Compute the mean squared error (MSE) loss between the predicted values and the ground truth labels: \n",
    "$$\\mathcal{L}_{MSE} = \\frac{1}{n} \\sum_{i=1}^n (\\bar{y_i} - y_i)^2$$\n",
    "3. Compute the gradients of the loss with respect to the weight and bias (see derivation in the course)\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial w_1} = \\sum_{i} 2 * (\\bar{y}_{i} - y_{i})*x_{i}$$\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial w_0} = \\sum_{i} 2 * (\\bar{y}_{i} - y_{i})$$\n",
    "4. Update the weights and bias using the gradients and a learning rate $\\eta$: \n",
    "$$w_1 \\leftarrow w_1 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_1}$$ \n",
    "$$w_0 \\leftarrow w_0 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_iters = 10000\n",
    "lr = 1e-3\n",
    "# Random init\n",
    "w1 = np.random.randn()\n",
    "w0 = np.random.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> **In-class exercise** The solution for this basic gradient descent definition is given, but the goal is for you to create a new cell and code the same behavior only from the equations (without looking at the solution straight away).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0117686947429183\n",
      "1.9707492714771357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c24f350cb74da3b850e2a07e2a32ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'3019dbad-c6c3-4cc8-a980-aaed7273141c': {'version…"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# In-class exercice\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "######################\n",
    "\n",
    "######################\n",
    "# Solution\n",
    "for iter in range(n_iters):\n",
    "    # Evaluate output of the model\n",
    "    y_bar = w1 * x + w0\n",
    "    # Compute the loss\n",
    "    loss = mse_loss(y, y_bar)\n",
    "    # Compute gradients\n",
    "    dLdw1 = 2 * np.sum((y_bar - y) * x)\n",
    "    dLdw0 = 2 * np.sum((y_bar - y))\n",
    "    # Update parameters\n",
    "    w1 = w1 - lr * dLdw1\n",
    "    w0 = w0 - lr * dLdw0\n",
    "p = scatter(x, y, title=\"Simple linear regression\")\n",
    "p.line(x, w1 * x + w0, line_width=3, line_alpha=0.6, color=\"red\", legend_label=r\"Learned model\")\n",
    "print(w1)\n",
    "print(w0)\n",
    "plot = (center_plot(p))\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0117662061425836\n",
      "1.9707506051845642\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1000\n",
    "lr = 0.001\n",
    "def gradient_descent(x, y, n_iter, lr):\n",
    "    # Initialize the parameters\n",
    "    w_1 = np.random.randn()\n",
    "    w_0 = np.random.randn()\n",
    "    # Perform gradient descent\n",
    "    for i in range(n_iter):\n",
    "        # 1. Calculate the predictions\n",
    "        y_bar = w_1 * x + w_0\n",
    "        # 2. Compute the loss\n",
    "        loss = mse_loss(y, y_bar)\n",
    "        # 3. Calculate the gradients\n",
    "        dw_1 = 2 * np.sum((y_bar - y) * x)\n",
    "        dw_0 = 2 * np.sum((y_bar - y))\n",
    "        # 4. Update the parameters\n",
    "        w_1 -= lr * dw_1\n",
    "        w_0 -= lr * dw_0\n",
    "    return w_1, w_0\n",
    "w_1, w_0 = gradient_descent(x, y, n_iter, lr)\n",
    "print(w_1)\n",
    "print(w_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Visualize the results.\n",
    "\n",
    "We can see how well our model fits to the observed data by plotting it against the observed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ce1c3a07ae441fae84d6f07bcf51cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'6136eab2-4bf3-4810-85cc-dd889451fa50': {'version…"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = scatter(x, y, title=\"Simple linear regression\")\n",
    "p.line(x, w_1 * x + w_0, line_width=6, line_alpha=0.6, color=\"red\", legend_label=r\"Learned model\")\n",
    "plot = (center_plot(p))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Observing our solution interactively\n",
    "\n",
    "In the following code, you can observe the behavior of the model by playing interactively with the properties of the original problem. \n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> Note that each change in the properties of the original problem requires to run the gradient descent algorithm entirely each time.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3339d04c0643d39602dbf809a74518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'2b214130-6b30-432e-8c6e-e9cad3b62bca': {'version…"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.tasks import RegressionLinearSolver\n",
    "explorer = RegressionLinearSolver()\n",
    "def solve(x, y):\n",
    "    w_1, w_0 = gradient_descent(x, y, n_iter, lr)\n",
    "    x_predict = np.linspace(np.min(x), np.max(x), 200)\n",
    "    y_model = w_1 * x_predict + w_0\n",
    "    return np.array(x_predict), np.array(y_model) #np.array(np.zeros(y_model.shape))\n",
    "\n",
    "explorer.solve = solve\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further\n",
    "> **Exercise 1 \\[Learning rate\\]**: Experiment with different learning rates (e.g., 0.001, 0.01, 0.1, 1) and observe how they affect the convergence of the gradient descent algorithm. Plot the convergence history (cost function value vs. iteration) for each learning rate.\n",
    "\n",
    "> **Exercise 2 \\[Initialization\\]**: Experiment with different initializations of the coefficients (zeros, random values, etc.) and observe their impact on the convergence of the gradient descent algorithm.\n",
    "\n",
    "> **Exercise 3 \\[Variants\\]**: Implement and compare different variants of gradient descent, such as stochastic gradient descent (SGD) and mini-batch gradient descent. Analyze their convergence properties and computational efficiency.\n",
    "\n",
    "> **Exercise 4 \\[Regularization\\]**: Implement Lasso and Ridge regression with gradient descent by incorporating the regularization terms into the cost function and gradient calculations. Compare their performance with the standard linear regression implementation and analyze their impact on the learned coefficients.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discovering automatic differentiation - `JAX`\n",
    "\n",
    "The previous implementation required us to perform manual differentiation of our loss function to understand how to update the parameters. However, large developments have been made in the field of **automatic differentiation**. \n",
    "\n",
    "The recent library [JAX](https://github.com/google/jax) extends NumPy with this automatic differentiation feature (*autograd*), while providing a functional approach to numerical computing, allowing for easy gradient computation and just-in-time (JIT) compilation. Its ability to handle complex and custom gradients makes JAX particularly well-suited for advanced research projects. Similar to NumPy, we strongly encourage you to learn JAX through the set of [tutorials](https://jax.readthedocs.io/en/latest/), but we will also provide here the explanation for all of the functions that we will use in this first exercise. After that, we will assume that knowledge of JAX should be found online. \n",
    "\n",
    "Note that `JAX` has been thought as an extension of `NumPy`, therefore an extremely large portion of its API simply mirrors the `NumPy` functions by adding automatic differentiation features to it.\n",
    "\n",
    "**Used functions**\n",
    "- `random.PRNGKey`: function to generate a key for the pseudorandom number generator. [Documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.PRNGKey.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "key = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Dataset.\n",
    "\n",
    "We can simply keep our previous approach to generating the dataset but we will rely on `jnp.ndarray` instead of `np.ndarray`. We also provide the code for splitting the dataset between a `training` and `validation` dataset, as discussed in the course\n",
    "\n",
    "**Used functions**\n",
    "- `random.split`: function to split a PRNGKey into a list of subkeys [Documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.split.html)\n",
    "- `random.uniform`: function to generate an array of uniformly distributed random numbers [Documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.uniform.html)\n",
    "- `random.normal`: function to generate an array of normally distributed random numbers [Documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.normal.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "true_w0 = 2\n",
    "true_w1 = 3\n",
    "key_0, key_1, key = random.split(key, 3)\n",
    "x = random.uniform(key_0, (100,))\n",
    "y = true_w0 + true_w1 * x + (random.normal(key_1, (100,)) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Splitting our dataset\n",
    "train_size = int(0.8 * len(x))\n",
    "x_train, x_valid = x[:train_size], x[train_size:]\n",
    "y_train, y_valid = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Loss function\n",
    "\n",
    "Similarly Define the cost function and its gradient.\n",
    "\n",
    "**Used functions**\n",
    "- `jnp.mean`: function to compute the mean of an array [Documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.mean.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "def model(x, w1, w0):\n",
    "    return w1 * x + w0\n",
    "\n",
    "def loss_function(x, y, w_1, w_0):\n",
    "    # Model function fO\n",
    "    y_pred = model(x, w_1, w_0)\n",
    "    # Calcul difference\n",
    "    residuals = y_pred - y\n",
    "    return jnp.mean(residuals**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "\n",
    "**Used functions**\n",
    "- `jit`: function to compile a function for faster execution [Documentation](https://jax.readthedocs.io/en/latest/jit.html)\n",
    "- `grad`: function to compute the gradient of a function [Documentation](https://jax.readthedocs.io/en/latest/jax.html#jax.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "grad_loss_function = grad(loss_function, argnums=[2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Implement the gradient descent algorithm.\n",
    "\n",
    "Note that nowhere in the code do we need to explicitly define the gradients of the different variables. Yet, the optimization will be performed adequately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent coefficients: [3.0778527] [1.9289745]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(key, x, y, lr=0.05, n_iter=1000):\n",
    "    m = x.shape\n",
    "    k_0, k_1 = random.split(key, 2)\n",
    "    w_0 = random.normal(k_0, (1,))\n",
    "    w_1 = random.normal(k_1, (1,))\n",
    "    loss_history = []\n",
    "    for _ in range(n_iter):\n",
    "        gradients = grad_loss_function(x, y, w_1, w_0)\n",
    "        #print(gradients[0])\n",
    "        w_1 -= lr * gradients[0]\n",
    "        w_0 -= lr * gradients[1]\n",
    "        loss_history.append(loss_function(x, y, w_1, w_0))\n",
    "    return w_1, w_0, loss_history\n",
    "\n",
    "key_gd, key = random.split(key, 2)\n",
    "w_1, w_0, loss_history = gradient_descent(key_gd, x_train, y_train)\n",
    "print(\"Gradient Descent coefficients:\", w_1, w_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Evaluate our performances\n",
    "\n",
    "Thanks to our previous split of the dataset, we are now able to evaluate the performances of our model on *unseen data*, which is the overarching goal of building such machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Gradient Descent: 0.036693253\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "y_valid_gd = w_1 * x_valid + w_0\n",
    "mse_gd = mean_squared_error(y_valid, y_valid_gd)\n",
    "print(\"MSE for Gradient Descent:\", mse_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Visualize the results.\n",
    "\n",
    "As previously we can witness our results, and also evaluate our solution with our interactive solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a869496919048db92355bb0dbb0611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'94aa98c0-a63c-4bec-a365-6263253c23bd': {'version…"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = scatter(np.array(x), np.array(y), title=\"Linear regression\")\n",
    "p.line(np.array(x), np.array(w_1 * x + w_0), line_width=6, line_alpha=0.6, color=\"red\", legend_label=r\"Learned model\")\n",
    "plot = (center_plot(p))\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b586d16b64460fbd5d3750437a625a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'7f8eaae9-3da4-47ef-824e-fb9acdc256a5': {'version…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.tasks import RegressionLinearSolver\n",
    "explorer = RegressionLinearSolver()\n",
    "global key\n",
    "key = random.PRNGKey(23)\n",
    "def solve(x, y):\n",
    "    global key\n",
    "    key_gd, key = random.split(key, 2)\n",
    "    w_1, w_0, loss_history = gradient_descent(key_gd, x, y)\n",
    "    x_predict = np.linspace(np.min(x), np.max(x), 200)\n",
    "    y_model = w_1 * x_predict + w_0\n",
    "    return np.array(x_predict), np.array(y_model) #np.array(jnp.zeros(y_model.shape))\n",
    "\n",
    "explorer.solve = solve\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further\n",
    "\n",
    "> You are encouraged to experiment in a similar way as outlined for NumPy with different learning rates, maximum number of iterations, and regularization techniques, as well as compare the performance (both accuracy and speed) of the implemented algorithms with `scikit-learn` built-in linear regression functions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "<a id=\"capacity\"></a>\n",
    "## Understanding model capacity and selection\n",
    "\n",
    "\n",
    "In real-life problem, we are aiming to find the parameters of a model, but we do not really know what is the _real_ function underlying this process. So what we can decide to select _any_ function of _any_ **capacity** (complexity of the function). One of the problem with that, is that if we have a too simple function, it will _underfit_ (it is not complex enough for our observations). On the opposite end, if we have a function which is too complex, it might be able to _fit through all training points exactly_ ... even though there is noise in our observations ! This is examplified in the following\n",
    "\n",
    "<img src=\"images/01_soa_function_families.png\" align=\"center\"/>\n",
    "\n",
    "We can observe this idea and play with it directly by trying to find a function approximating our previous observations with a polynomial function chosen to have a degree inside \\([1,2,8]\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "\n",
    "Depending on the _capacity_ of the model, what we can observe is that\n",
    "\n",
    "- `capacity too low   -> underfitting   : prediction variance >  noise variance`\n",
    "- `adequate capacity  -> good fit       : prediction variance == noise variance`\n",
    "- `capacity too high  -> overfitting    : prediction variance <  noise variance`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "A similar example can be given for a classification problem in two dimensions as follows\n",
    "\n",
    "<img src=\"images/01_underfit.png\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "In the following, we define the exercises that you should fill for this session. These go further than what we have seen together in the course, but they are based on the exact same principles, simply with slightly more complex definitions. We provide an overall guideline for successfully implementing each of the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> In this exercise, we will implement linear classification using NumPy and JAX. The goal of this exercise is to gain a better understanding of how linear classification works and how to implement it ourselves using our two first libraries of choice, namely NumPy and JAX. To complete this exercise, you will need to have a basic understanding of NumPy and JAX. You can use the resources provided in the previous exercises to learn more about these libraries.\n",
    "\n",
    "We help you out by first defining a simple linear classification problem to solve\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #410819; border-color: #cb2e47\">\n",
    "\n",
    "> **General reminder on the auto-grader**. \n",
    "> The auto-grader is looking for some _specifically-named function with a **given signature**_ in your notebook, so **make sure to keep the exact function name, arguments and returns** or this will be consider as an absent answer. However, your function can call other functions that you define here, and you can also even create new cells containing parts of your code (as long as the main function remains the same).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from typing import List, Tuple\n",
    "\n",
    "def create_dataset(\n",
    "    n_observations: int     = 200,\n",
    "    noise: float            = 0.2,\n",
    "    c1_center: List[float]  = [-2, -1],\n",
    "    c2_center: List[float]  = [2, 1]\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Function to create a linearly-separable dataset in Numpy.\n",
    "    Input:\n",
    "        n_observations    : (int) an array of observations\n",
    "        noise             : (float) amount of noise to add\n",
    "        c1_center         : (list) center (x, y) coordinate of the first class\n",
    "        c2_center         : (list) center (x, y) coordinate of the second class\n",
    "    Returns:\n",
    "        - \n",
    "    \"\"\"\n",
    "    # Create points\n",
    "    x_coords, y_class = make_blobs(n_samples=n_observations, centers=[c1_center, c2_center], n_features=2, cluster_std=0.55)\n",
    "    x_data = x_coords + (noise * np.random.randn(n_observations, 2))\n",
    "    # Set of classes (1 / -1)\n",
    "    y_classes = y_class\n",
    "    y_classes[y_classes == 0] = -1\n",
    "    return x_data, y_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.1 - Implement linear classification with NumPy\n",
    "\n",
    "> 1. Check the training data with two classes that are linearly separable.\n",
    "> 2. Initialize weights and bias.\n",
    "> 3. Implement the forward pass of the linear classifier.\n",
    "> 4. Implement the hinge loss for classification.\n",
    "> 5. Derive the gradients (backward pass) of the linear classifier.\n",
    "> 6. Implement gradient descent to optimize the weights and bias.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def hinge_loss_np(\n",
    "        y: np.ndarray, \n",
    "        y_bar: np.ndarray\n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    Numpy-based function to compute the Hinge loss.\n",
    "    Input:\n",
    "        y       : (np.ndarray) array of groundtruth classes\n",
    "        y_bar   : (np.ndarray) array of approximate classes\n",
    "    Returns:\n",
    "        loss    : (float) value of the loss function\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return loss\n",
    "\n",
    "def classify_np(\n",
    "        x: np.ndarray,\n",
    "        w0: float, \n",
    "        w1: float, \n",
    "        w2: float\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Numpy-based function to classify input points (model function)\n",
    "    Input:\n",
    "        x       : (np.ndarray) array of input observations\n",
    "        w0      : (float) bias\n",
    "        w1      : (float) coefficient weight 1\n",
    "        w2      : (float) coefficient weight 2\n",
    "    Returns:\n",
    "        y_bar   : (np.ndarray) array of infered classes (-1 / +1)\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return y_bar\n",
    "\n",
    "def gd_classification_np(\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray, \n",
    "        n_iter: int, \n",
    "        lr: float, \n",
    "        loss_func: Callable[[np.ndarray, np.ndarray], np.ndarray], \n",
    "        seed: int = 0\n",
    "    ) -> Tuple[float, float, float, List[float]]:\n",
    "    \"\"\"\n",
    "    This function performs gradient descent for linear classification model. \n",
    "    The function returns the weigths and evolution of the loss\n",
    "    Input:\n",
    "        x               : (np.ndarray) an array of observations\n",
    "        y               : (np.ndarray) an array of classes corresponding to the observations\n",
    "        n_iter          : (int) number of iterations\n",
    "        lr              : (float) learning rate\n",
    "        loss_function   : (function) loss function\n",
    "    Ouput:\n",
    "        w0              : (float) bias\n",
    "        w1              : (float) coefficient weight 1\n",
    "        w2              : (float) coefficient weight 2\n",
    "        loss_history    : (list) an array of loss values obtained from each iteration\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return w0, w1, w2, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further (optional)\n",
    "> Try to replace the Hinge loss by the cross-entropy loss in your implementation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_np(\n",
    "        y       : np.ndarray, \n",
    "        y_bar   : np.ndarray\n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    This function computes cross-entropy loss.\n",
    "    Input:\n",
    "        - y: an array of groud-truth classes\n",
    "        - y_bar: an array of outputs obtained from the model\n",
    "    Returns:\n",
    "        loss    : (float) value of the loss function\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.2 - Implement linear classification with JAX\n",
    "\n",
    "> 1. Initialize weights and bias.\n",
    "> 2. Define the loss function using the jax.nn.softmax_cross_entropy_with_logits function.\n",
    "> 3. Implement gradient descent to optimize the weights and bias.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def hinge_loss_jax(\n",
    "        y: jnp.ndarray, \n",
    "        y_bar: jnp.ndarray, \n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    JAX-based function to compute the hinge loss.\n",
    "    Input:\n",
    "        - y     : (jnp.ndarray) array of groud-truth classes\n",
    "        - y_bar : (jnp.ndarray) array of estimated classes\n",
    "    Returns:\n",
    "        loss    : (float) value of the loss function\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return loss\n",
    "\n",
    "def classify_jax(\n",
    "        x: jnp.ndarray,\n",
    "        w0: float, \n",
    "        w1: float, \n",
    "        w2: float\n",
    "    ) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    JAX-based function to classify input points (model function)\n",
    "    Input:\n",
    "        x       : (jnp.ndarray) array of input observations\n",
    "        w0      : (float) bias\n",
    "        w1      : (float) coefficient weight 1\n",
    "        w2      : (float) coefficient weight 2\n",
    "    Returns:\n",
    "        y_bar   : (jnp.ndarray) array of infered classes (-1)\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return y_bar\n",
    "\n",
    "def model_loss_jax(\n",
    "        x: jnp.ndarray, \n",
    "        y: jnp.ndarray, \n",
    "        w0: jnp.ndarray,  \n",
    "        w1: jnp.ndarray,  \n",
    "        w2: jnp.ndarray, \n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    JAX-based function which combines model inference (classify) and hinge loss.\n",
    "    This will allow to more easily use the automatic gradient function (grad) of JAX.\n",
    "    Input:\n",
    "        - x     : (jnp.ndarray) array of observations\n",
    "        - y     : (jnp.ndarray) array of groud-truth classes\n",
    "        - w0    : (float) bias\n",
    "        - w1    : (float) coefficient weight 1\n",
    "        - w2    : (float) coefficient weight 2\n",
    "    Returns:\n",
    "        loss    : (float) value of the loss function\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return loss\n",
    "\n",
    "def gd_classification_jax(\n",
    "        x: jnp.ndarray,\n",
    "        y: jnp.ndarray, \n",
    "        n_iter: int, \n",
    "        lr: float, \n",
    "        loss_func: Callable[[jnp.ndarray, jnp.ndarray], jnp.ndarray], \n",
    "        seed: int = 0\n",
    "    ) -> Tuple[float, float, float, List[float]]:\n",
    "    \"\"\"\n",
    "    This function performs gradient descent for linear classification model.\n",
    "    The function returns the weigths and evolution of the loss\n",
    "    Input:\n",
    "        x               : (jnp.ndarray) an array of observations\n",
    "        y               : (jnp.ndarray) an array of classes corresponding to the observations\n",
    "        n_iter          : (int) number of iterations\n",
    "        lr              : (float) learning rate\n",
    "        loss_function   : (function) loss function\n",
    "    Ouput:\n",
    "        w0              : (float) bias\n",
    "        w1              : (float) coefficient weight 1\n",
    "        w2              : (float) coefficient weight 2\n",
    "        loss_history    : (list) an array of loss values obtained from each iteration\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return w0, w1, w2, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.3 - Compare the results of the NumPy and JAX implementations.\n",
    "> 1. Plot the decision boundary for each implementation.\n",
    "> 2. Compare the training time and accuracy of each implementation.\n",
    "\n",
    "</div>\n",
    "\n",
    "**NB: Note** that this question will only be manually graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further (optional)\n",
    "> Implement a more complex dataset and compare the results of the NumPy and JAX implementations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> In this exercise, you will implement polynomial regression using NumPy and JAX. This should be a quite straightforward extension of what we have seen until now. We deliberately removed details of the implementation (list of points to adress) so that you can start defining your first entire machine learning setup by yourself.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression_dataset(\n",
    "        n_observations: int     = 200,\n",
    "        noise: float            = 0.2,\n",
    "        c1_center: List[float]  = [-2, -1],\n",
    "        c2_center: List[float]  = [2, 1]\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 2.1 - Implement polynomial regression using NumPy with gradient descent.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_np(\n",
    "    y: np.ndarray, \n",
    "    y_bar: np.ndarray\n",
    "  ) -> float:\n",
    "  \"\"\"\n",
    "    Numpy-based function to compute the _normalized_ MSE loss.\n",
    "    Input:\n",
    "        y       : (np.ndarray) array of groundtruth classes\n",
    "        y_bar   : (np.ndarray) array of approximate classes\n",
    "    Returns:\n",
    "        loss    : (float) value of the MSE\n",
    "  \"\"\"\n",
    "  ######################\n",
    "  # YOUR CODE GOES HERE\n",
    "  ######################\n",
    "  return loss\n",
    "\n",
    "def infer_np(\n",
    "        x: np.ndarray,\n",
    "        w0: float, \n",
    "        w1: float,\n",
    "        degree: int\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Numpy-based function to classify input points (model function)\n",
    "    Input:\n",
    "        x       : (np.ndarray) array of input observations\n",
    "        w0      : (float) bias\n",
    "        w1      : (float) coefficient weight 1\n",
    "        w2      : (float) coefficient weight 2\n",
    "    Returns:\n",
    "        y_bar   : (np.ndarray) array of infered classes (-1 / +1)\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return y_bar\n",
    "\n",
    "def gd_regression_np(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray, \n",
    "    n_iter: int, \n",
    "    lr: float, \n",
    "    degree: int,\n",
    "    loss_func: Callable[[np.ndarray, np.ndarray], np.ndarray], \n",
    "    seed: int = 0\n",
    "  ) -> Tuple[float, float, float, List[float]]:\n",
    "  \"\"\"\n",
    "    This function performs gradient descent for linear classification model.\n",
    "    Input:\n",
    "        x               : (np.ndarray) an array of observations\n",
    "        y               : (np.ndarray) an array of classes corresponding to the observations\n",
    "        n_iter          : (int) number of iterations\n",
    "        lr              : (float) learning rate\n",
    "        degree          : (int) polynomial degree\n",
    "        loss_function   : (function) loss function\n",
    "        seed            : (int) random number generator seed\n",
    "    Ouput:\n",
    "        w0              : (float) bias\n",
    "        w1              : (float) coefficient weight 1\n",
    "        loss_history    : (list) an array of loss values obtained from each iteration\n",
    "  \"\"\"\n",
    "  ######################\n",
    "  # YOUR CODE GOES HERE\n",
    "  ######################\n",
    "  return w0, w1, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 2.2. Implement polynomial regression using JAX with gradient descent.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def mse_loss_jax(\n",
    "        y: jnp.ndarray, \n",
    "        y_bar: jnp.ndarray, \n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    JAX-based function to compute the _normalized_ MSE loss.\n",
    "    Input:\n",
    "        y       : (np.ndarray) array of groundtruth classes\n",
    "        y_bar   : (np.ndarray) array of approximate classes\n",
    "    Returns:\n",
    "        loss    : (float) value of the MSE\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return loss\n",
    "\n",
    "\n",
    "def infer_jax(\n",
    "        x: jnp.ndarray,\n",
    "        w0: float, \n",
    "        w1: float, \n",
    "        degree: float\n",
    "    ) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    JAX-based function to classify input points (model function)\n",
    "    Input:\n",
    "        x       : (jnp.ndarray) array of input observations\n",
    "        w0      : (float) bias\n",
    "        w1      : (float) coefficient weight 1\n",
    "        w2      : (float) coefficient weight 2\n",
    "    Returns:\n",
    "        y_bar   : (jnp.ndarray) array of infered classes (-1)\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return y_bar\n",
    "\n",
    "def regress_loss_jax(\n",
    "        x: jnp.ndarray, \n",
    "        y: jnp.ndarray, \n",
    "        w0: jnp.ndarray,  \n",
    "        w1: jnp.ndarray,  \n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    JAX-based function which combines model inference (classify) and hinge loss.\n",
    "    This will allow to more easily use the automatic gradient function (grad) of JAX.\n",
    "    Input:\n",
    "        - x     : (jnp.ndarray) array of observations\n",
    "        - y     : (jnp.ndarray) array of groud-truth classes\n",
    "        - w0    : (float) bias\n",
    "        - w1    : (float) coefficient weight 1\n",
    "    Returns:\n",
    "        loss    : (float) value of the loss function\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    #####################\n",
    "    return loss\n",
    "\n",
    "def gd_regression_jax(\n",
    "        x: jnp.ndarray,\n",
    "        y: jnp.ndarray, \n",
    "        n_iter: int, \n",
    "        lr: float, \n",
    "        degree: int,\n",
    "        loss_func: Callable[[np.ndarray, np.ndarray], np.ndarray], \n",
    "        seed: int = 0\n",
    "    ) -> Tuple[float, float, float, List[float]]:\n",
    "    \"\"\"\n",
    "    This function performs gradient descent for linear classification model.\n",
    "    Input:\n",
    "        x               : (np.ndarray) an array of observations\n",
    "        y               : (np.ndarray) an array of classes corresponding to the observations\n",
    "        n_iter          : (int) number of iterations\n",
    "        lr              : (float) learning rate\n",
    "        degree          : (int) polynomial degree\n",
    "        loss_function   : (function) loss function\n",
    "        seed            : (int) random number generator seed\n",
    "    Ouput:\n",
    "        w0              : (float) bias\n",
    "        w1              : (float) coefficient weight 1\n",
    "        loss_history    : (list) an array of loss values obtained from each iteration\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    return w0, w1, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 2.3 - Compare the results of both implementations and the speed of the optimization algorithm.\n",
    "\n",
    "</div>\n",
    "\n",
    "**NB: Note** that this question will only be manually graded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "<a id=\"audio\"></a>\n",
    "# Audio applications\n",
    "\n",
    "In order to test our algorithms on audio and music data, we will work with several datasets. We will both be using well-known state-of-art datasets (through the TF dataset system). But first, we will rely on a simple dataset (`Musclefish`) that should be downloaded on your local computer first from this [link](https://nubo.ircam.fr/index.php/s/ByK4QL7nE4Mq5MA)\n",
    "\n",
    "**The following set of instructions will perform that automatically for you :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "!curl https://nubo.ircam.fr/index.php/s/ByK4QL7nE4Mq5MA/download/musclefish.zip --output musclefish.zip\n",
    "!unzip musclefish.zip\n",
    "!mkdir data\n",
    "!mv musclefish data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "## Dataset details\n",
    "\n",
    "  |**Type**|*Origin*|\n",
    "  |-------:|:---------|\n",
    "  |**Classification**|[*MuscleFish*](http://knight.cis.temple.edu/~vasilis/Courses/CIS750/Papers/muscle_fish.pdf) dataset|\n",
    "  |**Music-speech**|[*MIREX Recognition*](http://www.music-ir.org/mirex/wiki/2015:Music/Speech_Classification_and_Detection) set|\n",
    "  |**Source separation**|[*SMC Mirum*](http://smc.inesctec.pt/research/data-2/) dataset|\n",
    "  |**Speech recognition**|[*CMU Arctic*](http://festvox.org/cmu_arctic/) dataset|\n",
    "\n",
    "**Unzip the file and place the `musclefish` folder inside a `data` folder in the root of this notebook**\n",
    "For the first parts of the tutorial, we will mostly rely solely on the classification dataset. In order to facilitate the interactions, we provide a dataset class called `AudioSupervisedDataset` that will allow to import all audio datasets along the tutorials. This class also contains a set of holders and will allow us to perform batch-wise gradient descent.\n",
    "\n",
    "```Python\n",
    "class AudioSupervisedDataset():\n",
    "    \"\"\"\n",
    "    Helper class to import datasets\n",
    "    % class_path  : Path to the dataset (string)\n",
    "    % type       : Type of dataset (string: 'classify', 'plain', 'metadata')\n",
    "    \"\"\" \n",
    "    audio_files\n",
    "    labels\n",
    "    labels_names\n",
    "    num_examples \n",
    "    num_classes \n",
    "```\n",
    "\n",
    "We also provide a simplified function `import_dataset` that is demonstrated below.\n",
    "\n",
    "***\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "**_Exercise_**  \n",
    "\n",
    "  1. Launch the import procedure and check the corresponding structure\n",
    "  2. Code a count function that prints the name and number of examples for each classes \n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from cml.data import import_dataset, AudioSupervisedDataset\n",
    "data_path = \"data/\"\n",
    "batch_size = 16\n",
    "# Instantiate the dataset class\n",
    "train_dataset = import_dataset(data_path, \"musclefish\", 'train', batch_size=batch_size)\n",
    "# Generate a batch of data from the train dataset\n",
    "batch_x, batch_y = next(train_dataset)\n",
    "# Print the shape of the input and output batch tensors\n",
    "print(batch_x.shape)  # (16, 44100)\n",
    "print(batch_y.shape)  # (16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "#%% Q-0.1.2 - Count function to print the number of examples in each class along with class label\n",
    "\n",
    "n_batch = 0\n",
    "train_dataset._reset_generator()\n",
    "for batch_x, batch_y in iter(train_dataset):\n",
    "    n_batch += 1\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "\n",
    "print(n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "We will rely on a set of spectral transforms that allow to obtain a more descriptive view over the audio information. As most of these are out of the scope of the machine learning course, we redirect you to a [signal processing course](https://ccrma.stanford.edu/~jos/sasp/) proposed by [Julius O. Smith](https://ccrma.stanford.edu/~jos/).  \n",
    "\n",
    "The following functions to compute various types of transforms are given as part of the basic audio dataset class, in the `cml.data.audio` package\n",
    "\n",
    "  |**Name**|*Transform*|\n",
    "  |-------:|:----------|\n",
    "  |`stft`       |[Short-term Fourier transform](https://en.wikipedia.org/wiki/Short-time_Fourier_transform)|\n",
    "  |`mel`  |[Mel scale](https://en.wikipedia.org/wiki/Mel_scale) transform|\n",
    "  |`chroma` |[Chromas vector](https://en.wikipedia.org/wiki/Harmonic_pitch_class_profiles)|\n",
    "  |`cqt`        |[Constant-Q](https://en.wikipedia.org/wiki/Constant_Q_transform) transform|\n",
    "\n",
    "In order to perform the various computations, we provide the following function, in the `AudioSupervisedDataset` which performs the different transforms on a complete dataset.  \n",
    "\n",
    "``` Python\n",
    "dataset.transform(index, name)\n",
    "    \"\"\" index   : Specific index in our dataset \"\"\"\n",
    "    \"\"\" name    : Name of the transform to apply \"\"\"\n",
    "\n",
    "# The name can be selected in \n",
    "\"stft\"      # Power spectrum (STFT)\n",
    "\"mel\"       # Spectrum in Mel scale\n",
    "\"chroma\"    # Chroma vectors\n",
    "\"cqt\"       # Constant-Q transform\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "**Exercise**  \n",
    "\n",
    "  1. Launch the transform computation procedure and check the corresponding structure\n",
    "  2. For each class, select a random element and plot its various transforms on a single plot. You should obtain plots similar to those shown afterwards.\n",
    "  3. For each transform, try to spot major pros and cons of their representation.\n",
    "  \n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# 0.2 - Pre-process the audio to obtain spectral transforms \n",
    "power_spec = train_dataset.transform(0, \"stft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "#%% Q-0.2.2 - Plot the various transforms \n",
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "### Features\n",
    "\n",
    "<div markdown = \"1\">\n",
    "\n",
    "As you might have noted from the previous exercice, most spectral transforms have a very high dimensionality, and might not be suited to exhibit the relevant structure of different classes. To that end, we provide a set of functions for computing several spectral features in the `cml.data` package, we redirect interested readers to this [exhaustive article](http://recherche.ircam.fr/anasyn/peeters/ARTICLES/Peeters_2003_cuidadoaudiofeatures.pdf) on spectral features computation.\n",
    "\n",
    "  |**File**|*Transform*|\n",
    "  |-------:|:----------|\n",
    "  |`spectral_centroid`|Spectral centroid|\n",
    "  |`spectral_bandwidth`|Spectral bandwidth|\n",
    "  |`spectral_contrast`|Spectral contrast|\n",
    "  |`spectral_flatness`|Spectral flatness|\n",
    "  |`spectral_rolloff`|Spectral rolloff|\n",
    "\n",
    "Once again, we provide a function to perform the computation of different features on a complete set. Note that for each feature, we obtain the temporal evolution in a vector. Therefore, for further learning tasks, if you wish to obtain simplified spaces, you might need to compute the mean and standard deviation of each feature.\n",
    "\n",
    "``` Python\n",
    "dataset.feature(index, name)\n",
    "    \"\"\" index   : Specific index in our dataset \"\"\"\n",
    "    \"\"\" name    : Name of the feature to obtain \"\"\"\n",
    "\n",
    "# Name can be chosen inside the following\n",
    "\"loudness\"    # Loudness\n",
    "\"centroid\"    # Spectral centroid\n",
    "\"bandwidth\"   # Spectral bandwidth\n",
    "\"contrast\"    # Spectral contrast\n",
    "\"flatness\"    # Spectral flatness\n",
    "\"rolloff\"     # Spectral rolloff\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "  1. Launch the feature computation procedure and check the corresponding structure\n",
    "  2. This time for each class, superimpose the plots of various features on a single plot, along with a boxplot of mean and standard deviations. You should obtain plots similar to those shown afterwards.\n",
    "  3. What conclusions can you make on the discriminative power of each feature ?\n",
    "  4. Perform scatter plots of the mean features for all the dataset, while coloring different classes.\n",
    "  5. What conclusions can you make on the discriminative power of mean features ?\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# 0.3 - Compute temporal spectral features\n",
    "power_spec = train_dataset.feature(0, \"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "#%% Q-0.3.2 - Plot the various features \n",
    "\n",
    "# Use these styles for boxplot\n",
    "boxprops=dict(linewidth=3, color='white')\n",
    "whiskerprops=dict(linewidth=3, color='white')\n",
    "medianprops=dict(linewidth=2.5, color='firebrick')\n",
    "flierprops = dict(markeredgecolor='white', markerfacecolor='firebrick')\n",
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "#%% Q-0.3.4 - Observe the distribution of classes for different features\n",
    "\n",
    "# This allows to use 3D rendering in matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.figure(figsize=(12,8))\n",
    "# Create a vector of random colors for each class\n",
    "colorVect = np.zeros((3, len(data_struct[\"class_names\"])));\n",
    "for c in range(len(data_struct[\"class_names\"])):\n",
    "    colorVect[:,c] = np.random.rand(3);\n",
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "That's it for this tutorial, now remember that we can use any form of description (features) as a basis for learning algorithms. We will see in the next tutorial what we an do with these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}